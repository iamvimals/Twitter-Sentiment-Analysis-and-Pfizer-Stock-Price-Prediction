{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f2ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vileg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import wordnet\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cf911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from .csv file and store it as a dataframe\n",
    "tweets_data = pd.read_csv('Twitter-Sentiment-Analysis-and-Pfizer-Stock-Price-Prediction/csv/vaccination_all_tweets.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89502c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338158543359250433</td>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337855739918835717</td>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337854064604966912</td>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id             user_name              user_location  \\\n",
       "0  1340539111971516416            Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1  1338158543359250433           Albert Fong          San Francisco, CA   \n",
       "2  1337858199140118533              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3  1337855739918835717         Charles Adler     Vancouver, BC - Canada   \n",
       "4  1337854064604966912  Citizen News Channel                        NaN   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             405          1692             3247          False   \n",
       "1             834           666              178          False   \n",
       "2              10            88              155          False   \n",
       "3           49165          3933            21853           True   \n",
       "4             152           580             1473          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "\n",
       "                                            hashtags               source  \\\n",
       "0                                 ['PfizerBioNTech']  Twitter for Android   \n",
       "1                                                NaN      Twitter Web App   \n",
       "2  ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "3                                                NaN      Twitter Web App   \n",
       "4     ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
       "\n",
       "   retweets  favorites  is_retweet  \n",
       "0         0          0       False  \n",
       "1         1          1       False  \n",
       "2         0          0       False  \n",
       "3       446       2129       False  \n",
       "4         0          0       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4fae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228207 entries, 0 to 228206\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   id                228207 non-null  int64 \n",
      " 1   user_name         228205 non-null  object\n",
      " 2   user_location     161296 non-null  object\n",
      " 3   user_description  211189 non-null  object\n",
      " 4   user_created      228207 non-null  object\n",
      " 5   user_followers    228207 non-null  int64 \n",
      " 6   user_friends      228207 non-null  int64 \n",
      " 7   user_favourites   228207 non-null  int64 \n",
      " 8   user_verified     228207 non-null  bool  \n",
      " 9   date              228207 non-null  object\n",
      " 10  text              228207 non-null  object\n",
      " 11  hashtags          178504 non-null  object\n",
      " 12  source            228088 non-null  object\n",
      " 13  retweets          228207 non-null  int64 \n",
      " 14  favorites         228207 non-null  int64 \n",
      " 15  is_retweet        228207 non-null  bool  \n",
      "dtypes: bool(2), int64(6), object(8)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# examine the contents of all the columns\n",
    "tweets_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f6259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date column to datetime stamp\n",
    "tweets_data['date'] = pd.to_datetime(tweets_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27dbc3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228207 entries, 0 to 228206\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   id                228207 non-null  int64         \n",
      " 1   user_name         228205 non-null  object        \n",
      " 2   user_location     161296 non-null  object        \n",
      " 3   user_description  211189 non-null  object        \n",
      " 4   user_created      228207 non-null  object        \n",
      " 5   user_followers    228207 non-null  int64         \n",
      " 6   user_friends      228207 non-null  int64         \n",
      " 7   user_favourites   228207 non-null  int64         \n",
      " 8   user_verified     228207 non-null  bool          \n",
      " 9   date              228207 non-null  datetime64[ns]\n",
      " 10  text              228207 non-null  object        \n",
      " 11  hashtags          178504 non-null  object        \n",
      " 12  source            228088 non-null  object        \n",
      " 13  retweets          228207 non-null  int64         \n",
      " 14  favorites         228207 non-null  int64         \n",
      " 15  is_retweet        228207 non-null  bool          \n",
      "dtypes: bool(2), datetime64[ns](1), int64(6), object(7)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed5ec4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, user_name, user_location, user_description, user_created, user_followers, user_friends, user_favourites, user_verified, date, text, hashtags, source, retweets, favorites, is_retweet]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values\n",
    "tweets_data[tweets_data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7cf0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228207, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns total rows and columns, respectively as a tuple\n",
    "tweets_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b2672",
   "metadata": {},
   "source": [
    "<h2>Clean tweets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af8b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    # Add whitespace to the end of every tweet\n",
    "    tweets['clean_tweet'] = tweets['text'].map(lambda x: x + \" \") \n",
    "    # Remove http links\n",
    "    tweets['clean_tweet'] = tweets['clean_tweet'].map(lambda x: re.sub(r'http.*', '', x))\n",
    "    # Remove special characters and numbers\n",
    "    tweets['clean_tweet'] = tweets['clean_tweet'].map(lambda x: re.sub(r\"[^a-zA-Z#]\", ' ', x))\n",
    "    # Lowercase all tweets\n",
    "    tweets['clean_tweet'] = tweets['clean_tweet'].map(lambda x: x.lower())\n",
    "    # Tokenize words, eliminate stop words and store them back\n",
    "    stopword_list = stopwords.words('english')\n",
    "    for i in range(0, len(tweets['clean_tweet'])):\n",
    "        tokens = word_tokenize(tweets['clean_tweet'].iloc[i])\n",
    "        clean_tokens = [t for t in tokens if t not in stopword_list]\n",
    "        tweets['clean_tweet'].iloc[i] = clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e34bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vileg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ad51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vileg\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "clean_tweets(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e338a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data['clean_tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9718c8",
   "metadata": {},
   "source": [
    "<h2>Lemmatize tweets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweets):\n",
    "    \n",
    "    for i in range(len(tweets)):\n",
    "        # Pos-tag each word in tweet\n",
    "        for word in [tweets[i]]:\n",
    "            pos_tag_list = nltk.pos_tag(word)\n",
    "        # Convert pos-tag to be wordnet compliant\n",
    "        wordnet_tags = []\n",
    "        for j in pos_tag_list:\n",
    "            # Adjective\n",
    "            if j[1].startswith('J'):\n",
    "                wordnet_tags.append(wordnet.ADJ)\n",
    "            # Noun\n",
    "            elif j[1].startswith('N'):\n",
    "                wordnet_tags.append(wordnet.NOUN)\n",
    "            # Adverb\n",
    "            elif j[1].startswith('R'):\n",
    "                wordnet_tags.append(wordnet.ADV)\n",
    "            # Verb\n",
    "            elif j[1].startswith('V'):\n",
    "                wordnet_tags.append(wordnet.VERB)\n",
    "            # Default to noun\n",
    "            else:\n",
    "                wordnet_tags.append(wordnet.NOUN)\n",
    "        # Lemmatize each word in tweet\n",
    "        lem_words = []\n",
    "        for k in range(len(tweets[i])):\n",
    "            lem_words.append(lemmatizer.lemmatize(tweets[i][k], pos=wordnet_tags[k]))\n",
    "        lem_tweet = ' '.join(lem_words)\n",
    "        tweets[i] = lem_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d07c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d43742",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_tweet(tweets_data.clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12244714",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data['clean_tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ab0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data['clean_tweet'] = tweets_data['clean_tweet'].map(lambda x: x.replace('#', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b93053",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data['clean_tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130b966",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac281fd",
   "metadata": {},
   "source": [
    "<h3>1. What are the most common words?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the tweets to form a single tweet\n",
    "all_tweets_combined = ' '.join([tweet for tweet in tweets_data['clean_tweet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the single tweet into words and store it in a list\n",
    "all_tweets_words_list = all_tweets_combined.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c059273",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d090e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the frequency distribution for first 30 words\n",
    "plt.figure(figsize = (12, 5))\n",
    "plt.xticks(fontsize = 13, rotation = 90)\n",
    "freq_dist = nltk.FreqDist(all_tweets_words_list)\n",
    "freq_dist.plot(30, cumulative = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud with word frequencies \n",
    "wordcloud = WordCloud(width = 900, height = 500, max_words = 500, max_font_size = 100, relative_scaling = 0.5, colormap = 'Blues', normalize_plurals = True).generate_from_frequencies(freq_dist)\n",
    "plt.figure(figsize = (17, 14))\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212837e",
   "metadata": {},
   "source": [
    "<h3>2. What is the frequency of each word?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a90bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = nltk.FreqDist(all_tweets_words_list)\n",
    "word_freq_df = pd.DataFrame({'Word': list(word_freq.keys()), 'Frequency': list(word_freq.values())}).sort_values(by = ['Frequency'], ascending = False)\n",
    "word_freq_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of most frequent words\n",
    "\n",
    "word_freq_df = word_freq_df.nlargest(columns=\"Frequency\", n = 25) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=word_freq_df, x= \"Word\", y = \"Frequency\")\n",
    "ax.set_ylabel('Frequency', fontsize=16)\n",
    "ax.set_xlabel('Word', fontsize=16)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\", fontsize=12)\n",
    "ax.set_title(\"Most Popular Words\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bae89",
   "metadata": {},
   "source": [
    "<h3>3. What time sees the most number of tweets?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b19016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe grouping the number of tweets by hour of the day\n",
    "\n",
    "tweets_hour_df = pd.DataFrame(tweets_data.groupby(tweets_data['date'].dt.hour)['clean_tweet'].count()).reset_index()\n",
    "tweets_hour_df = tweets_hour_df.rename(columns={'date': 'Hour', 'clean_tweet': 'Frequency'})\n",
    "tweets_hour_df.Hour = tweets_hour_df.Hour.replace([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0], ['12:00 AM', '1:00 AM', '2:00 AM', '3:00 AM', '4:00 AM', '5:00 AM', '6:00 AM', '7:00 AM', '8:00 AM', '9:00 AM', '10:00 AM', '11:00 AM', '12:00 AM', '1:00 PM', '2:00 PM', '3:00 PM', '4:00 PM', '5:00 PM', '6:00 PM', '7:00 PM', '8:00 PM', '9:00 PM', '10:00 PM', '11:00 PM'])\n",
    "tweets_hour_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of Tweet Counts by Hour\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=tweets_hour_df, x= \"Hour\", y = \"Frequency\")\n",
    "ax.set_ylabel('Frequency', fontsize=16)\n",
    "ax.set_xlabel('Hour', fontsize=16)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\", fontsize=12)\n",
    "ax.set_title(\"Tweets by Time of Day\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33693fc0",
   "metadata": {},
   "source": [
    "<h3>4. Which days sees the most number of tweets?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148eb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe grouping the number of tweets by hour of the day\n",
    "tweets_day_df = pd.DataFrame(tweets_data.resample('D', on='date')['clean_tweet'].count()).reset_index().sort_values(by='clean_tweet', ascending=False)\n",
    "tweets_day_df = tweets_day_df.rename(columns={'date': 'Day', 'clean_tweet': 'Frequency'})\n",
    "tweets_day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80112ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tweeted_days = tweets_day_df.sort_values(by = ['Frequency'], ascending=False)[:30]\n",
    "top_tweeted_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff97250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of Tweet Counts by Day\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=top_tweeted_days, x= top_tweeted_days.Day.dt.date, y = \"Frequency\")\n",
    "ax.set_ylabel('Frequency', fontsize=16)\n",
    "ax.set_xlabel('Date', fontsize=16)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\", fontsize=12)\n",
    "ax.set_title(\"Days with the Most Tweets\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75283bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00088496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5e0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
